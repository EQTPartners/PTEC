# Prompt Tuning for Sector Classification - Master Thesis
The repository for the master thesis research regarding company sector classification, containing experiments comparing different methods for sector classification

# Installation
After cloning this repository, the necessary packages can be installed with:
```bash
pip install -r requirements.txt
pip install -e .

# if using a vertex ai notebook with CUDA
pip3 install torch==1.13.1+cu117 --extra-index-url https://download.pytorch.org/whl/cu117 --no-cache-dir
```

# Reproducibility 
All experiments, including hyperparameter search, can be reproduced by running the following batch files:

```bash
bash preprocessing/preprocessing.sh
bash sectors/experiments/run_experiments_gpu.sh
bash sectors/experiments/run_experiments_cpu.sh
```

# Usage
The scripts can also be run individually:

## Preprocessing
The preprocessed data for the hatespeech dataset is already contained in this repository. However, it can be rerun with
```bash
python preprocessing/get_dataset.py
python preprocessing/preprocess_data.py # this line will take ~10 min as it summarizes long descriptions and keyword lists
```

The preprocessed dataset can be augmented by applying paraphrasing with vicuna:
```bash
python preprocessing/paraphrase_augmentation.py
```
This will create a new dataset `data/[DATASET]/train_augmented.json`.

## Running The Experiments
For test runs, all the following commands include the `--model_name=bigscience/bloom-560m` flag, as this can easily be run on a cpu. However, it can also be replaced with other huggingface hosted LLaMa or Bloom models. By default it uses `huggyllama/llama-7b`. All experimental results will be saved as `json` files in the `results/[DATASET]/` directory.

### N-shot experiments
```bash
python sectors/experiments/nshot/nshot.py --model_name bigscience/bloom-560m
```

In order to use `gpt-3.5-turbo` as a model for n-shot prompting, a `.env` file with the OpenAI API credentials needs to be added to the root directory of this repository:

```bash
OPENAI_SECRET_KEY = "secret key"
OPENAI_ORGANIZATION_ID = "org id"
```

### Embedding Promximity
For these experiments, the embeddings still have to be generated by running the following code

```bash
python embedding_proximity/generate_embeddings.py --model_name bigscience/bloom-560m
# for augmented data
python embedding_proximity/generate_embeddings.py --model_name bigscience/bloom-560m --augmented augmented
```

Then, the following code runs all embedding proximity experiments: 
```bash
python embedding_proximity/vector_similarity.py --model_name bigscience/bloom-560m
python embedding_proximity/vector_similarity.py --model_name bigscience/bloom-560m --augmented augmented

python embedding_proximity/vector_similarity.py --type RadiusNN --model_name bigscience/bloom-560m
python embedding_proximity/vector_similarity.py --type RadiusNN --model_name bigscience/bloom-560m --augmented augmented

python embedding_proximity/classification_head/classification_head.py --model_name bigscience/bloom-560m
python embedding_proximity/classification_head/classification_head.py --model_name bigscience/bloom-560m --augmented augmented
```

### Prompt Tuning
```bash
python prompt_tuning/prompt_tune.py --model_name bigscience/bloom-560m --interrupt_threshold 0.01
python prompt_tuning/prompt_tune.py --model_name bigscience/bloom-560m --interrupt_threshold 0.01 --augmented augmented
```

### PTEC
```bash
python prompt_tuning/prompt_tune.py --model_name bigscience/bloom-560m --head ch --scheduler exponential --interrupt_threshold 0.01
python prompt_tuning/prompt_tune.py --model_name bigscience/bloom-560m --head ch --scheduler exponential --interrupt_threshold 0.01 --augmented augmented
```

# Other Resources
For an example of applying Trie Search, see `notebooks/constrained_beam_search.ipynb`


# Citation
If you use or refer to this repository in your research, please cite it as:

## BibTeX
```bash
@misc{buchner2023PTEC,
    title={Accelerating Thematic Investment with Prompt Tuned Pretrained Language Models},
    author={Valentin Buchner and Lele Cao and Jan-Christoph Kalo and Vilhelm von Ehrenheim},
    year={2023},
    publisher={EQT},
    version={1.0},
    url={https://github.com/EQTPartners/PTEC}
}
```

## APA
Buchner, V., Cao, L., Kalo, J.-C., & von Ehrenheim, V. (2023). Accelerating Thematic Investment with Prompt Tuned Pretrained Language Models (Version 1.0) [Software]. EQT. https://github.com/EQTPartners/PTEC

## MLA
Buchner, Valentin, et al. "Accelerating Thematic Investment with Prompt Tuned Pretrained Language Models." Version 1.0, EQT, 2023, https://github.com/EQTPartners/PTEC.